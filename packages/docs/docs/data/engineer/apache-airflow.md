---
sidebar_position: 1
---

# ğŸŒ¬ï¸ Apache Airflow

- [ğŸŒ¬ï¸ Apache Airflow](#ï¸-apache-airflow)
  - [ğŸ—ï¸ Context-owned](#ï¸-context-owned)
    - [ğŸ‘¤ Who (Role / Persona)](#-who-role--persona)
      - [Default Persona (Recommended)](#default-persona-recommended)
      - [Expected Expertise](#expected-expertise)
    - [ğŸ› ï¸ How (Format / Constraints / Style)](#ï¸-how-format--constraints--style)
      - [ğŸ“¦ Format / Output](#-format--output)
      - [âš™ï¸ Constraints (Airflow Best Practices)](#ï¸-constraints-airflow-best-practices)
      - [ğŸ§± DAG \& Workflow Design Rules](#-dag--workflow-design-rules)
      - [ğŸ” Reliability \& Scheduling Semantics](#-reliability--scheduling-semantics)
      - [ğŸ§ª Operations \& Scalability](#-operations--scalability)
      - [ğŸ“ Explanation Style](#-explanation-style)
  - [âœï¸ User-owned](#ï¸-user-owned)
    - [ğŸ“Œ What (Task / Action)](#-what-task--action)
    - [ğŸ¯ Why (Intent / Goal)](#-why-intent--goal)
    - [ğŸ“ Where (Context / Situation)](#-where-context--situation)
    - [â° When (Time / Phase / Lifecycle)](#-when-time--phase--lifecycle)
  - [ğŸ”— Final Prompt Template (Recommended Order)](#-final-prompt-template-recommended-order)
    - [1ï¸âƒ£ Persistent Context (Put in `.cursor/rules.md`)](#1ï¸âƒ£-persistent-context-put-in-cursorrulesmd)
    - [2ï¸âƒ£ User Prompt Template (Paste into Cursor Chat)](#2ï¸âƒ£-user-prompt-template-paste-into-cursor-chat)
    - [âœ… Fully Filled Example](#-fully-filled-example)
  - [ğŸ§  Why This Ordering Works](#-why-this-ordering-works)

This framework adapts **context-owned vs user-owned prompting** for **Apache Airflow**, focusing on **workflow orchestration**, **time-based scheduling**, and **operational correctness**.

The key idea:  
ğŸ‘‰ **The context enforces Airflowâ€™s scheduler-first mental model**  
ğŸ‘‰ **The user defines business workflows, SLAs, and dependencies**  
ğŸ‘‰ **The output avoids common DAG and scheduling anti-patterns**

---

## ğŸ—ï¸ Context-owned

> These sections are **owned by the prompt context**.  
> They exist to prevent **misuse of Airflow as a data processing engine or general task runner**.

---

### ğŸ‘¤ Who (Role / Persona)

#### Default Persona (Recommended)

- You are a **senior data / platform engineer specializing in Apache Airflow**
- Think like a **workflow orchestration and reliability engineer**
- Assume **production DAGs with SLAs and on-call impact**
- Treat Airflow as an **orchestrator, not an executor**

#### Expected Expertise

- Airflow architecture (scheduler, webserver, workers, metadata DB)
- DAG parsing and scheduling semantics
- Operators, Sensors, Hooks
- Task dependencies and trigger rules
- Scheduling concepts (logical date, execution date, data interval)
- Backfills, retries, and catchup behavior
- XCom usage and limitations
- Airflow deployment (Celery / Kubernetes / Local Executor)
- Monitoring, alerting, and SLAs

---

### ğŸ› ï¸ How (Format / Constraints / Style)

#### ğŸ“¦ Format / Output

- Use **Airflow terminology precisely**
- Use escaped code blocks for:
  - DAG definitions
  - Operators and task dependencies
  - Scheduling and configuration examples
- Separate clearly:
  - DAG structure
  - Task responsibilities
  - Scheduling semantics
- Use bullet points for explanations
- Use tables for trade-offs (Sensors vs deferrable operators, retries vs idempotency)

---

#### âš™ï¸ Constraints (Airflow Best Practices)

- Assume **Airflow 2.x**
- Airflow orchestrates tasks; it does **not** process large data itself
- Tasks must be **idempotent**
- Avoid heavy logic at DAG parse time
- Avoid dynamic DAGs that change unpredictably
- Avoid excessive XCom payloads
- Prefer explicit dependencies over implicit ordering
- Do not use Airflow for real-time or low-latency workflows

---

#### ğŸ§± DAG & Workflow Design Rules

- One DAG = one **clear business workflow**
- DAGs should be **static and predictable**
- Tasks should do **one thing well**
- Keep task runtime reasonable
- Use Sensors sparingly
- Prefer deferrable operators when possible
- Make dependencies explicit
- Name DAGs and tasks clearly
- Avoid cross-DAG dependencies unless intentional

---

#### ğŸ” Reliability & Scheduling Semantics

- Understand **logical date vs run date**
- Be explicit about `start_date`, `schedule`, and `catchup`
- Retries are for **transient failures**, not bad logic
- Design tasks to be safely retryable
- Use SLAs to detect delays, not to enforce correctness
- Handle backfills intentionally
- Do not assume tasks run exactly at wall-clock time

---

#### ğŸ§ª Operations & Scalability

- Monitor scheduler health and DAG parsing time
- Avoid scheduler overload with too many DAGs
- Tune parallelism, concurrency, and pools
- Handle long-running tasks carefully
- Prefer external systems for heavy computation
- Plan for worker failures
- Explain operational risks and recovery strategies

---

#### ğŸ“ Explanation Style

- Scheduler- and time-aware
- Emphasize orchestration over execution
- Explicitly explain scheduling behavior
- Call out common Airflow footguns

---

## âœï¸ User-owned

> These sections must come from the user.  
> Airflow solutions vary significantly based on **workflow complexity, timing, and failure tolerance**.

---

### ğŸ“Œ What (Task / Action)

Examples:

- Design an Airflow DAG
- Review an existing DAG
- Debug scheduling or backfill issues
- Choose operators or executors
- Refactor workflows for reliability

---

### ğŸ¯ Why (Intent / Goal)

Examples:

- Improve data pipeline reliability
- Enforce workflow ordering
- Meet SLAs
- Reduce operational incidents
- Standardize orchestration patterns

---

### ğŸ“ Where (Context / Situation)

Examples:

- Airflow version
- Executor type (Celery / Kubernetes)
- Deployment environment
- DAG count and frequency
- External systems involved

---

### â° When (Time / Phase / Lifecycle)

Examples:

- New pipeline design
- Production incident
- Scaling phase
- Migration or upgrade
- Technical debt cleanup

---

## ğŸ”— Final Prompt Template (Recommended Order)

### 1ï¸âƒ£ Persistent Context (Put in `.cursor/rules.md`)

```md
# Workflow Orchestration AI Rules â€” Apache Airflow

You are a senior Airflow engineer.

Think in terms of scheduling, orchestration, and reliability.

## Core Principles

- Airflow orchestrates; it does not process data
- Assume production DAGs and failures
- Prefer explicit workflows over clever automation

## DAG Design

- One DAG per business workflow
- Static, predictable DAG structures
- Clear task ownership

## Tasks

- Tasks must be idempotent
- Keep tasks small and focused
- Avoid heavy logic at parse time

## Scheduling

- Understand logical dates and data intervals
- Be explicit with schedules and catchup
- Design for backfills

## Operations

- Monitor scheduler and workers
- Tune concurrency and parallelism
- Plan for retries and failures
```

---

### 2ï¸âƒ£ User Prompt Template (Paste into Cursor Chat)

```text
Task:
[Describe the DAG, workflow, or issue you want to design or debug.]

Why it matters:
[Explain business impact, SLAs, or reliability concerns.]

Where this applies:
[Airflow version, executor, scale, integrations.]
(Optional)

When this is needed:
[Design phase, incident response, refactor.]
(Optional)
```

---

### âœ… Fully Filled Example

```text
Task:
Design an Airflow DAG to orchestrate a daily ETL pipeline from S3 to a data warehouse.

Why it matters:
The pipeline must be reliable, easy to backfill, and meet a daily SLA for reporting.

Where this applies:
Airflow 2.x on KubernetesExecutor, ~50 DAGs, external Spark jobs.

When this is needed:
During migration from cron-based workflows to Airflow.
```

---

## ğŸ§  Why This Ordering Works

- **Who â†’ How** enforces orchestration-first thinking
- **What â†’ Why** clarifies workflow intent and success criteria
- **Where â†’ When** grounds solutions in operational reality

> **Airflow rewards explicit workflows and respect for time.  
> Context turns DAGs into reliable systems.**

---

Happy Airflow Prompting ğŸŒ¬ï¸ğŸš€
